<title>
IMPST: A New Interactive Self-Training Approach to Segmentation Suspicious Lesions in Breast MRI.
</title>

<text>

<abstract>
Breast lesion segmentation in magnetic resonance (MR) images is one of the most important parts of clinical diagnostic tools. Pixel classification methods have been frequently used in image segmentation with two supervised and unsupervised approaches up to now. Supervised segmentation methods lead to high accuracy, but they need a large amount of labeled data, which is hard, expensive, and slow to be obtained. On the other hand, unsupervised segmentation methods need no prior knowledge and lead to low performance. However, semi-supervised learning which uses not only a few labeled data, but also a large amount of unlabeled data promises higher accuracy with less effort. In this paper, we propose a new interactive semi-supervised approach to segmentation of suspicious lesions in breast MRI. Using a suitable classifier in this approach has an important role in its performance; in this paper, we present a semi-supervised algorithm improved self-training (IMPST) which is an improved version of self-training method and increase segmentation accuracy. Experimental results show that performance of segmentation in this approach is higher than supervised and unsupervised methods such as K nearest neighbors, Bayesian, Support Vector Machine, and Fuzzy c-Means.
</abstract>

<sections.0>
I
reast cancer is one of the common malignant diseases among women in ran and many other parts of the world. n 2010, the ran epartment of ealth has announced that over 7,000 women are diagnosed with this disease and 1400 die of breast cancer every year in ran. edical imaging plays a pivotal role in breast cancer care including detection, diagnosis, and treatment monitoring. urrently, mammography is the primary screening modality that is widely used to detect and diagnose breast cancer. nfortunately, it has some limitations.[1β€“5] 10-30% breast cancersβ€² are not detected by mammography and its positive predictive value is less than 35%.[6] ence, the use of other imaging modality such as magnetic resonance imaging ()[78] is increasing and it is used simultaneously as an appropriate scenario with mammography especially for women at high risk. ome studies have shown that  is superior to x-ray mammography and sonography in order to determine breast cancer tumor volume.[9β€“11]
n the recent years, several methods have been proposed to segment lesions in mammography and  data. he references[1213] provide comprehensive information about them. hese methods can be categorized into three groups: i) contour-based segmentation such as active contour algorithm.[14β€“17] ii) egion-based segmentation techniques.[1819] iii) lassification-based segmentation that includes supervised and unsupervised methods.
upervised-based segmentation such as eural etworks[2021] and upport ector achines [][22] lead to high accuracy, but they require a large amount of labeled data, which is hard, expensive, and slow to be obtained. urthermore, they cannot use unlabeled data to train classifiers. n the other hand, unsupervised learning methods such as arkov andom ield[23] and uzzy  eans ()[24] remove the costs of labeling and do not use label of training data. o these methods need no prior knowledge and will have lower performance with respect to supervised methods.
o solve these problems, we propose a semi-supervised approach for segmentation of breast lesions in this paper. everal semi-supervised algorithms such as -raining,[25] o-raining,[26] and xpectation aximization ()[27] have been presented, although none of them have been used for breast lesions segmentation in . t should be mentioned that many of the presented methods in breast lesion segmentation used only the intensity value as a feature for each pixel, which is subject to image noise, patient motion, and  artifacts.[28β€“30] extures are one of the most important image attributes and can be distinguished objects with different patterns. ibbs et al.[31] used texture analysis in diagnosis of benign and malignant breast lesions.
n this paper, we propose a semi-supervised pixel-by-pixel classification method based on texture analysis in order to achieve a high performance. n fact, our proposed method has two main stages. n the first stage, improved self-training () classifier is trained only with a labeled image. n the next stage, nondeterministic unlabeled data is obtained through simple thresholding and this classifier is retrained with them to reach high accuracy. his paper is organized as follows: n section 2, we introduce three methods that were used for extracting features from breast s. elf-raining algorithm is also presented in this section. he proposed approach will be explained in section 3. ection 4 investigates the experimental results of the proposed approach and compares the results with the supervised and unsupervised methods. inally, discussion and conclusion come in section 5.INTRODUCTION
Breast cancer is one of the common malignant diseases among women in Iran and many other parts of the world. In 2010, the Iran Department of Health has announced that over 7,000 women are diagnosed with this disease and 1400 die of breast cancer every year in Iran. Medical imaging plays a pivotal role in breast cancer care including detection, diagnosis, and treatment monitoring. Currently, mammography is the primary screening modality that is widely used to detect and diagnose breast cancer. Unfortunately, it has some limitations.[1β€“5] 10-30% breast cancersβ€² are not detected by mammography and its positive predictive value is less than 35%.[6] Hence, the use of other imaging modality such as magnetic resonance imaging (MRI)[78] is increasing and it is used simultaneously as an appropriate scenario with mammography especially for women at high risk. Some studies have shown that MRI is superior to x-ray mammography and sonography in order to determine breast cancer tumor volume.[9β€“11]
In the recent years, several methods have been proposed to segment lesions in mammography and MRI data. The references[1213] provide comprehensive information about them. These methods can be categorized into three groups: i) contour-based segmentation such as active contour algorithm.[14β€“17] ii) Region-based segmentation techniques.[1819] iii) Classification-based segmentation that includes supervised and unsupervised methods.
Supervised-based segmentation such as Neural Networks[2021] and Support Vector Machines [SVM][22] lead to high accuracy, but they require a large amount of labeled data, which is hard, expensive, and slow to be obtained. Furthermore, they cannot use unlabeled data to train classifiers. On the other hand, unsupervised learning methods such as Markov Random Field[23] and Fuzzy C Means (FCM)[24] remove the costs of labeling and do not use label of training data. So these methods need no prior knowledge and will have lower performance with respect to supervised methods.
To solve these problems, we propose a semi-supervised approach for segmentation of breast lesions in this paper. Several semi-supervised algorithms such as B-Training,[25] Co-Training,[26] and Expectation Maximization (EM)[27] have been presented, although none of them have been used for breast lesions segmentation in MRI. It should be mentioned that many of the presented methods in breast lesion segmentation used only the intensity value as a feature for each pixel, which is subject to image noise, patient motion, and MR artifacts.[28β€“30] Textures are one of the most important image attributes and can be distinguished objects with different patterns. Gibbs et al.[31] used texture analysis in diagnosis of benign and malignant breast lesions.
In this paper, we propose a semi-supervised pixel-by-pixel classification method based on texture analysis in order to achieve a high performance. In fact, our proposed method has two main stages. In the first stage, improved self-training (IMPST) classifier is trained only with a labeled image. In the next stage, nondeterministic unlabeled data is obtained through simple thresholding and this classifier is retrained with them to reach high accuracy. This paper is organized as follows: In section 2, we introduce three methods that were used for extracting features from breast MRIs. Self-Training algorithm is also presented in this section. The proposed approach will be explained in section 3. Section 4 investigates the experimental results of the proposed approach and compares the results with the supervised and unsupervised methods. Finally, discussion and conclusion come in section 5.
</sections.0>

<sections.1>
M  
mage ataset. In this paper, we used the PIDER Breast MRI dataset (https://imaging.nci.nih.gov/ncia). This dataset includes breast MRI images from five patients and their ground truth (GT) segmentation that has been identified by a radiologist manually. GT is used as a reference for performance evaluation of segmentation methods in our experiments.Region of Interest SelectionSince automatic segmentation of medical images is a challenging task and still an unsolved problem for many applications; experience of a radiologist can increase algorithm performance. Here, we present an interactive segmentation approach according to the identified region of interest (ROI). In our approach, an experienced radiologist examines and draws ROIs on MR image data with the help of image analysis software at first, and then, we give these ROIs as an input image to algorithm. Since the ROI is defined by placing a box with limited size -that completely contains the region of breast lesion, the segmentation complexity is reduced. A sample of ROI has been shown in Figure 1.Figure 1Region of interestFeature Extraction MethodsSince textures are one of the most important characteristics of an image and also radiologists rely on textures to make diagnostic decisions, features extraction basis from texture is most widely used in medical image processing.[32] Texture feature attempts to identify gray level variations between adjacent pixels in the image.[33]In this paper, we used three categories of texture feature: histogram statistics, co-occurrence, and run length matrix. For each pixel in the region of interest, we used a block 5*5 whose feature values are assigned to central pixel of block. Histogram statistics (six features) describes the intensity distribution within the block, such as mean and standard deviation.Co-occurrence matrices[34] which measure the joint probability of two adjacent pixels along a given direction with co-occurring values i and j are calculated for 0Β°, 45Β°, 90Β°, and 145Β°. An average co-occurrence matrix is then computed for each texture block since no directional variations in texture are expected. Some of the equations of these texture features are given as follows.[34]Notation:p(i, j): (i, j)-the entry in a normalized gray-tone spatial-dependence matrix.px(i): is the i-th entry in the marginal-probability matrix obtained by summing the rows of N: is the number of distinct gray levels in the equalized image.1. Angular second2. Contrast3. CorrelationWhere ΞΌX and ΟƒX are the mean and standard deviations PX, Respectively.4. Variance5. Inverse difference moment6. EntropyWe calculated 22 features form co-occurrence matrices that measure joint probability of two nearest pixels in four directions.The run-length matrix masseurs the abrasiveness of a texture in a given direction ΞΈ. Direction is the number of runs of pixels with a gray-level and a run length. A gray-level run is defined as a set of consecutive pixels with the same gray value in the given direction.[35] 11 features obtained from run-length matrix for same direction ΞΈ = 0Β°, 45Β°, 90Β°, and 145Β°. And the number of gray levels to use in both co-occurrence and run length matrices is 8. Some of the equations of these texture features are given as follows:[34]1. Short run emphasis2. Long run emphasis3. Gray level nonuniformity4. Run-length nonuniformityWhere I(i, j) is defined as the number of runs with pixels of gray level i and run length, j. nr is also the total number of runs. The texture features are listed in appendix. Totally, we extracted 39 texture features for each pixel.Semi-Supervised Classification MethodsIn traditional machine learning, only labeled data were used for classification. In general, obtaining labeled data is not only a hard working, expensive, and time consuming process, but also need human effort. Meanwhile, unlabeled data are easy to collect and there are a few ways to use them. Recently, semi-supervised learning addresses this problem.[36] By having a large number of unlabeled and a few numbers of labeled data, we can have a better classifier.Since semi-supervised learning needs less human effort and has higher accuracy, it is interesting both in practical and theoretical fields. Medical image processing is one of the tasks in which collecting labeled data is difficult; therefore, semi-supervised learning is used in many image processing applications.[3738]Pixel classification is one of the image segmentation methods which are based on two approaches: Supervised[22] and unsupervised learning. But as it was mentioned, obtaining labeled data is a difficult task and the unsupervised segmentation methods need no prior knowledge and lead to low performance. So to solve these problems, we propose a pixel classification method based on semi-supervised learning which uses the potential of a large labeled data in order to increase the segmentation accuracy. Semi-supervised learning methods have never been used in breast MRI images segmentation.
</sections.1>

<sections.2>
P 
n this paper, a semi-supervised approach is presented for breast lesion segmentation which use from  algorithm. igure 2 shows an overall view of this approach. or better understanding of the working process of the , we describe this proposed model in detail at first. s mentioned before, our approach has two main stages in training step. n the first stage, three feature sets are extracted for each pixel of training images according to section 2. hen, an image is chosen randomly as a labeled training data and is given to a radiologist for manual segmentation. n this approach, we do not need a radiologist to indicate the exact lesion region, but selecting a small region (about 20% of image) of the lesion is enough. he igure below illustrates how an image is labeled by a radiologist.
igure 2llustration of proposed approach. As it is shown in the Figure 3, indicating this region by a radiologist is easier than indicating the exact lesion region. After manual labeling, these pixels are selected for primary training of IMPST. The remaining trained images are used as unlabeled data. In the next stage, a simple thresholding method is applied to get nondeterministic labeled data from unlabeled ones. Then, IMPST classifier is retrained with nondeterministic labeled data in an iterative manner. The IMPST algorithm is explained in the next section.
Figure 3Manual segmentation by radiologistIn the testing step, for segmenting an image, the first mentioned three features sets are extracted for each pixel of the image. Then, these pixels are entered to the trained classifier to be labeled.
Self-TrainingSelf-training is a technique commonly used for semi supervised learning. In self-training, a classifier is first trained with the small amount of labeled data. The classifier is then used to classify the unlabeled data. The unlabeled data, which is now labeled, are compared with a threshold and are added to the labeled training data.The classifier is retrained and the procedure is repeated. Table 1 and Figure 4 show the pseudo code and overall view of the self-training algorithm, respectively.Table 1Pseudo code of self-training algorithmFigure 4Illustration of self-training algorithmThe weakness which restricts the performance of self-training is simple decision policy used to select unlabeled data. To surmount this problem, we propose IMPST algorithm.IMPST AlgorithmAs described in section 2, the IMPST algorithm creates an initial weak classifier based solely on the labeled examples at first. The classifier is then used to classify the unlabeled training data. These unlabeled samples along with their predicted labels are added to the training set. But self-training algorithm uses a simple decision policy to add unlabeled samples to training data. This weakness can decrease the performance of algorithm.To overcome this problem, we defined a more sophisticated decision policy. The improved self-training algorithm has been described in Table 2 gives a set L of labeled training samples and a set U of unlabeled training ones. We extract three feature sets and then use them to train a classifier C.Table 2Pseudo code of IMPST algorithmThe algorithm iterates the following procedure for the maximum number of iteration iteration No. First, it recognizes the unlabeled examples in U classifier B. The label predictions and corresponding class probabilities are recorded in (Label, Prob). The class probabilities Prob is regarded as the confidence estimates for better selection. Secondly, the algorithm selects some reliable unlabeled data Reliable_Unlabeled data for which 1) the assigned labels by classifier B and sample thresholding be equal and 2) each probability label be greater than a specific threshold that is determined by problem information. Unlabeled data that do not satisfy these two constraints are filtered, but the others are added to labeled data examples L and removed from unlabeled data U in next iteration. These decision polices reinforce the self-training which selects the most confident labeled example. Hereby, the performance of algorithm is increased.
</sections.2>

<sections.3>
E 
n previous section, we proposed our semi-supervised approach for breast lesion segmentation in s in detail. n this section, as mentioned before, the performance of this method is investigated by using  reast  dataset (https://imaging.nci.nih.gov/ncia). his dataset includes breast  images and their ground truth () segmentation that have been identified by a radiologist manually.
 is used as a reference for performance evaluation of segmentation methods in our experiments. ere, we used four images for training process that one of them is a labeled image and the others are unlabeled ones. hen, 120 pixels (equivalent with labeled part with radiologist) (60 lesions and 60 nlesion) are chosen from labeled image. lso, 400 pixels (200 lesions and 200 nlesion) are randomly selected from nondeterministic labeled images that are obtained through sample thresholding. ereby, we have the total of 120 labeled and 1200 nondeterministic labeled pixels for the training classifier.
n the next step, 12 breast images from dataset are used as the test images. ue to space limitation, we only show the result of 5 out of 12 test images in separate ables. he s of these images and their s have been shown in two first rows of able 3. inally, the result of the all 12 test images is demonstrated in able 4.
able 3egmentation results for supervised and proposed methods. Table 4Segmentation results for IMPST and other (K.N.N, SVM, Bayesian, FCM) classifier (12 test data)The analysis methods described in this paper is numerically implemented using Matlab 7.9 (R 2009b).
Evaluation CriteriaMany different measures for evaluating the performance of an algorithm have been proposed such as volume overlap ratio, specificity, sensitivity, precision, accuracy and etc. First, we give a definition of some expressions in Table 5.Table 5Definition of some expressions1. AccuracyThis criterion is used to measure the similarity between assigned labels by computer algorithm and real labels given by a radiologist.2. PrecisionUnlike accuracy, precision criterion is used to measure reproducibility or repeatability of assigning a label in the same condition.3. SpecificityThis criterion measures the proportion of negatives which are correctly identified.4. SensitivityThis criterion measures the proportion of actual positives which are correctly identified. These two latest measures are closely related to the concepts of errors.5. Volume overlap ratioIn this study, we also use the overlap ratio to quantify how well the computer results and the radiologist's delineation agree. If Pc denote the set of lesion pixels which came from the computer, algorithm result and Pr denote the set of lesion pixels which is came from the radiologist's segmentation, the volume overlap ratio (VOR) is defined as:In which the β�© operator is logical and, β�� is the logical OR. It takes value between [0 1], when it is zero. It means that there is no overlap and one means the exact overlap.[39]6. Other criterionWe also describe the accuracy with other parameters: True Positive Volume Fraction (TPVF), True Negative Volume Fraction (TNVF), false positive volume fraction (FPVF), and false negative volume fraction (FNVF). These parameters are defined as follows:[40]We just use the two of these volume fractions and the sum of them: TPVF and TNVF.Performance Evaluation for Supervised ClassifiersBefore evaluating the segmentation performance in semi-supervised method, we investigate the performance of supervised methods in breast MRI image segmentation at first. For this purpose, three supervised classifiers K-Nearest Neighbors (KNN with k=10), SVM, and Bayesian are trained separately using 120 labeled data. Then, we compute evaluation measures such as VOR, accuracy, and precision of these classifiers for test data using Equation 11-19. Tables 6β€“8 represent segmentation results of the three supervised classifiers on five test images and their segmentation results have been illustrated in rows 3, 4, and 5 of Table 3. The blue and violet pixels indicate true and false positives, respectively, in segmented images. As it can be observed in Table 4, supervised methods cannot produce acceptable results when we have a few labeled data.Table 6Segmentation results for SVM classifierTable 7Segmentation results for K.N.N classifierTable 8Segmentation results for Bayesian classifierPerformance Evaluation for Unsupervised MethodIn this section, we evaluated the performance of Fuzzy c-Means methods as an unsupervised algorithm in breast MRI images segmentation. According to Tables 3, 4, and 9 the Fuzzy c-Means cannot produce proper results compare to IMPST.Table 9Segmentation results for fuzzy c-meansPerformance Evaluation for Proposed ApproachIn this experiment, IMPST uses Bayesian classifier as the basic classifier. To train this classifier, we set the iteration parameters iteration No to be 400. In Figure 5, classification error rate in each iteration has been shown. After training the classifier, we compute evolution measures for test images. The segmentation results of IMPST have been shown in Table 10 and the row 7 of Table 3illustrates segmented images.Figure 5Classification error rate in each iterationTable 10Segmentation results for IMPST classifierThe quantitative evaluation results of all 12 test images are provided in Table 4. The VOR was (59.53Β±12.09) (MeanΒ±Std dev), (60.0Β±18.74), (55.47Β±17.44), (58.68Β±24.95) and (67.73Β±16.72) between computer and radiologist for K.N.N, SVM, Bayesian, Fuzzy c-Means and IMPST classifiers, respectively. As it is evident in Table 4, there are statistically significant difference between proposed approach and supervised methods. Generally, our proposed method can produce more proper results compared to supervised and unsupervised method only with 20% labeled data.To evaluate the performance of the classifiers, Receiver operating characteristic (ROC) analysis also is performed. ROC is based on statistical decision theory and it has been applied widely to the evaluation of clinical performance. The area under the ROC curve is referred Az index. It is used as a measure of the classification performance.A higher Az indicates better classification performance because a larger value of True Positive (TP) is achieved at each value of False Positive (FP). The value of AZ is 1.0 when the diagnostic detection has perfect performance, which means that TP rate is 100% and FP rate is 0%. The values of AZ have been shown in Table 11.Table 11The values of AZThe ROC diagram is shown in the Figure 6.Figure 6Average ROC curves obtained on all testing images using supervised, unsupervised and semi-supervised approaches
</sections.3>

<sections.4>
C  
n this paper, semi-supervised approach is presented as a new approach for breast lesion segmentation in s. his approach evaluates through 9 criteria; ccuracy, , recision, pecificity, ensitivity, rue ositive olume raction, and rue egative olume raction. he results shows that the proposed method has a higher performance compared to supervised methods, due to interaction with a radiologist.  number of interesting points have been revealed from several test images:

upervised classifiers have a high performance in image segmentation when they are trained with a large amount of data. ut in many cases (such as image processing problems), as repeatedly mentioned, integrating labeled data is expensive. ccording to the results of experiments, supervised classifiers cannot produce the appropriate results when a few labeled data available. In conditions that limited labeled data are available, presented semi-supervised classifier can produce more appropriate results compared to supervised classifiers by exploiting information which exist in labeled and unlabeled dataBy adding a more precise decision policy to Self-Training algorithm, IMPST classifier trains a confident learner. Hence, this approach improves accuracy and precision of segmented images according to experimental resultsUnsupervised methods remove the cost of labeling, but, since these methods donβ€²t need any prior knowledge about problem, they have lower performance with respect to supervised and semi- supervised methods.
</sections.4>

<sections.5>
A
he list of three categories (tatistics, o-occurrence atrix, un-ength atrix) textural features have been used in this paper is given as follows:
tatistic

ean. SkewnessAbsolute deviationVarianceKurtosisStandard deviation

Co-occurrence matrix

Uniformity/Energy/Angular second momentEntropyDissimilarityContrast/InertiaInverse differenceCorrelationHomogeneity/Inverse difference momentAutocorrelationCluster shadeCluster prominenceMaximum probabilitySum of squaresSum averageSum varianceSum entropyDifference varianceDifference entropyInformation measures of correlation (1)Information measures of correlation (2)Maximal correlation coefficientInverse difference normalized (INN)Inverse difference moment normalized (IDN)

Run-length matrix

Short Run Emphasis (SRE)Long Run Emphasis (LRE)Gray-Level Nonuniformity (GLN)Run Length Nonuniformity (RLN)Run Percentage (RP)Low Gray-Level Run Emphasis (LGRE)High Gray-Level Run Emphasis (HGRE)Short Run Low Gray-Level Emphasis (SRLGE)Short Run High Gray-Level Emphasis (SRHGE)Long Run Low Gray-Level Emphasis (LRLGE)Long Run High Gray-Level Emphasis (LRHGE)
</sections.5>

<sections.6>
B

eza zmi, received his  degree in lectrical ngineering from mirkabir university of technology, ehran, ran in 1990 and his  and h. D degrees in Electrical Engineering from Tarbiat Modares university, Tehran, Iran in 1993 and 1999 respectively. Since 2001, he has joined Alzahra university, Tehran, Iran. He was an expert member of Image Processing and Multi-Media working groups in ITRC (From 2003 to 2004), Optical Character Recognition working group in supreme council of information and communication technology (From 2006 to 2007) and Security Information Technology and Systems working groups in ITRC (From 2006 to 2008). He was Project Manager and technical member of many industrial projects.

Narges Norozi, received the B.Sc degree in computer engineering from Abhar University, Zanjan, Iran in 2008. Currently she is doing MASc in Artificial Intelligence from Alzahra University, Tehran, Iran. Her research interests include Medical Image processing, Machine Vision and Pattern Recognition.

Robab Anbiaee received her MD degree in Medical College of Shahid Sadooghi University, Yazd, Iran in 1991-1998. She is completed her residency at Medical College of Shahid Beheshti University of Medical Sciences, Iran, Tehran in 2001-2004. Also she is currently Assistant Professor in Department of Radiation oncology for Medical College of Shahid Beheshti University, Iran, Tehran.

Leila Salehi, received his B.Sc. degree in software engineering from Abhar University, Abhar, Iran in 2007 and she is currently study M.Sc. in artificial intelligence in Alzahra University, Tehran. She is interested in medical image processing research

Azardokht Amirzadi received the B.Sc degree in computer engineering from Oloom Fonoon University, Babol, Iran in 2008. Currently she is doing MASc in Artificial Intelligence from Alzahra University, Tehran, Iran. Her research interests include machine learning and computer vision, medical image processing.
</sections.6>

</text>
