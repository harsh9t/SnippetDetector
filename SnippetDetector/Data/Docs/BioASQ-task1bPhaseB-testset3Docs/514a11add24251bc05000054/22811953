<title>
Multi-field-of-view strategy for image-based outcome prediction of multi-parametric estrogen receptor-positive breast cancer histopathology: Comparison to Oncotype DX.
</title>

<text>

<sections.0>
I
redicting disease aggressiveness and outcome for estrogen receptor-positive (+) breast cancers (a) patients allows for selective employment of therapeutic options. pecifically, identifying which women will benefit from adjuvant chemotherapy over and above the standard hormonal therapy will help limit the use of chemotherapy to more aggressive a.[1] rognosis and treatment in early stage + a are often guided by the ncotype  genomic assay (enomic ealth, nc.), which produces a quantitative recurrence score () correlated with likelihood for recurrence.[1] owever, recent work has suggested that molecular assays do not provide additional prognostic power over tumor morphology (e.g. grading) and immunohistochemistry (e.g. receptor status).[23] isual analysis of tumor grade in a histopathology has shown significant value in predicting patient outcome;[14] yet high inter- and intra-clinician variability[5] has limited its use in clinical practice. onversely, a quantitative, reproducible, and computerized prognostic tool that uses only digitized a histopathology slides would be invaluable for predicting prognosis and guiding therapy. ranslational advantages of an image-based predictor over its molecular counterparts include a reduced cost per test, shorter time delay between biopsy and treatment, and easier access to patients in developing countries such as ndia and hina.
n microscopy, pathologists implicitly partition an entire histopathology slide into many fields of views (s) and incorporate image features from each  to arrive at a diagnostic decision for the entire slide. revious computerized approaches to whole-slide classification, however, have primarily involved the extraction of image features (for the training of a classifier) from within empirically selected s.[67] he empirical selection of s for computerized analysis of a histopathology slides presents two main concerns. irst, it is a subjective and time-consuming task that requires manual intervention by an expert, an issue that would impede the development of a truly automated classification system. econd, a is known to contain intratumoral heterogeneity,[8] whereby different types of cancer (e.g. ductal carcinoma in situ and invasive ductal cancer) and levels of malignancy (e.g. low and intermediate grades) may be present in a single histopathology slide. his phenomenon suggests that multiple s of various sizes will be needed depending on the different types of image features extracted and classification tasks performed.
n this paper, we present a multi- framework[9] to perform robust, reproducible classification of entire + a histopathology slides based on low, intermediate, and high disease aggressiveness while addressing limitations arising from both manual  selection and a heterogeneity. he multi- classifier is fundamentally different from traditional multi-scale (i.e. multi-resolution) approaches.[1011] n image processing, multi-scale schemes are often used to interpret contextual information over different image resolutions.[10] ost multi-scale frameworks, which operate by exposing a single  to classifiers at multiple image resolutions, perform well when quantifying large-scale image patterns. nalyzing local object density (or other localized descriptors), however, is more challenging since object density remains invariant to changes in scale (although our visual perception and ability to detect individual objects within the image will vary).
he multi- framework is used to predict a outcome by combining image-based features from 34 immunohistochemistry () stained and hematoxylin and eosin ( and ) stained histopathology slides. ur multi- scheme uses a fixed image scale and extracts image features at s of different sizes, a highly desirable attribute in heterogeneous images where it is not clear which  sizes will contain class discriminatory information. irst, a slide is split into s of a fixed size and relevant image features are extracted.  supervised classifier makes an initial class decision for each  and the decisions for all s are aggregated to make a single class prediction for the specific  size. his procedure is repeated for a variety of  sizes, from which the class predictions at all  sizes are aggregated to arrive at a single decision for the entire slide. ence there is no need to empirically determine the optimal  size for classification; rather this approach combines class predictions from image features across all  sizes. lass predictions are made by two multi- classifiers applied independently to image features describing (1) nuclear architecture and (2) vascular density from the same patient. hese class predictions are subsequently combined to form a multi-parametric prediction for the patient.
he 34 protein is a popular indicator of angiogenesis and, hence, tumor growth and metastasis.[12] reviously, both qualitative[13] and quantitative[14] assessments of 34  stained slides have characterized  staining via β€�hotspotsβ€�, i.e. manually selected s; yet, the pitfalls associated with manual  selection suggest that hotspot-based predictions may not accurately represent 34 expression in an entire slide. n this paper, vascular density is automatically extracted from 34  stained histopathology and used as the sole image-based feature to quantify angiogenic activity. pecifically, color deconvolution,[15] which takes advantage of light-absorbing properties of histological staining, is used to automatically isolate the brown diaminobenzidine () compound signifying 34 expression. he extent of  staining in a particular  is defined as vascular density and used as a feature in the multi- framework.
n prior work, researchers have demonstrated the ability to model and quantify tumor morphology in  and  stained histology through the construction of various graphs.[71617]  graph (e.g. oronoi diagram) is constructed by drawing edges between relevant tissue structures (e.g. nuclei) in a particular fashion. raph-based features describing the spatial arrangement of these structures (e.g. oronoi cell area) are then defined to quantify tissue architecture. n this paper, nuclear architecture is quantified in  and  stained histopathology by constructing three graphs (oronoi diagram, elaunay triangulation, and minimum spanning tree) using individual cancer nuclei as nodes. he nuclei are first identified automatically by isolating the blue hematoxylin stain, which preferentially stains nuclear material, via color deconvolution.[15]  total of 50 graph-based features describing the spatial arrangement of cancer nuclei are extracted from each .[718] ote that, while both vascular density and nuclear architecture are widely considered to have prognostic value, their biological foundations are very different. his suggests that these two feature classes are complementary and that their combination may produce an improved predictor of patient outcome.
he main contributions of this work are the following:

evelopment and quantitative evaluation of image-based architectural and vascular features for patient outcome prediction in whole-slide + a histopathology and. Synergistic combination of image-based features from multi-parametric histological studies to achieve an improved prognostic prediction of patient outcome.

While the ideal ground truth for evaluation of prognostic tools like the one described in this work is long-term patient outcome (i.e. survival data), this type of data is very difficult to obtain. In lieu of patient outcome, we utilize Oncotype DX RS as a relative ground truth. Oncotype DX, which produces a quantitative RS between 0 and 100, is a molecular assay that has been clinically validated to predict the likelihood of 10-year distant recurrence and the expected benefit from adjuvant chemotherapy for early-stage, ER+ BCa patients.[1] Specifically, we evaluate the ability of the multi-FOV framework (in conjunction with vascular and architectural features) to distinguish patients with low, intermediate, and high Oncotype DX RS.
The rest of the paper is organized as follows. In the section β€�multi-FOV frameworkβ€� , we present the theory and methodology behind the multi-FOV framework. It is followed by the sections β€�experimental design,β€� β€�results and discussionβ€�, and β€�conclusion.β€�
Multi-FOV FrameworkAn image scene C=(C,g) is defined as a 2D set of pixels c β�� C with associated intensity function g and class label y β�� {0,1}. For each C and FOV size Ο„ β�� T, a grid containing FOVs DΟ„={dΟ„1, dΟ„2,.... dΟ„M} is constructed, where dΟ„m
β�� C,m β�� {1,2,..., M} is a square FOV with edge length of pixels. We define f(dΟ„m) as the function that extracts features from each dΟ„m. Grid construction and feature extraction are repeated likewise for each Ο„ β�� T.Theoretical Motivation for Consensus-based ApproachThe theory supporting consensus over multiple FOVs demonstrates that a consensus predictor is inherently superior to classification at individual FOV sizes. A consensus predictor over multiple FOV sizes is defined as H (D)= EΟ„ [H (DΟ„, Ο„)], where D = {DΟ„: β�€Ο„ β�� T} is the collective data over all FOV sizes, H(DΟ„, Ο„) is a meta-classifier (integrated FOV size prediction via individual FOV classifier) for each Ο„, and EΟ„ is the expectation of H(DΟ„, Ο„) at FOV size Ο„ β�� T. The mean squared error of classification at individual FOV sizes is given by eΟ„ = EΟ„ [yβ€“H(DΟ„, Ο„)] and the error of the consensus predictor is given by eA = [yβ€“H(D)]2.Note that the consensus classifier for multiple FOV sizes is similar to Bagging.[19] However, instead of combining weak learners, independent predictors at different FOV sizes (reasonable assumption since different information is discernible at different FOV sizes in heterogeneous images) are used as the β€�weakβ€� classifiers used to build the β€�strongβ€� consensus result. To this end, Proposition 1 ensures that the consensus error eA will always be less than the mean error eΟ„ of individual FOV size classifiers.Integrated FOV Size Prediction via Individual FOV ClassifierA pre-trained classifier h(dΟ„M, f) β�� {0,1} is first used to assign an initial class decision to each individual FOV dΟ„ with associated features f. Subsequently, decisions are aggregated for all FOVs DΟ„ to achieve a combined decision H(DΟ„, Ο„) at a single FOV size Ο„ β�� T.Algorithm 1: Individual FOV ClassifierInput: Image C. FOV sizes T. Classified h(dΟ„m, f).Output: Aggregate prediction H(DΟ„, Ο„) for each FOV size Ο„ β�� T
for All Ο„ β�� T doFrom C, define M, Ο„ Γ— Ο„ FOVs DΟ„= {dΟ„1, dΟ„2,.... dΟ„M}.Extract features f from dΟ„m, β�€m β�� M.Apply classifier h(dΟ„m, f) for initial classification of each dΟ„m.Make aggregate predication  over all FOVs DΟ„.end for
Experimental DesignDatasetThe multi-FOV classifier is leveraged for the task of quantifying BCa disease outcome by distinguishing tumors based on Oncotype DX RS. CD34 immunohistochemistry (IHC) and hematoxylin and eosin (H and E) stained histopathology images from 29 patients (9 low RS, 11 intermediate RS, 9 high RS) were digitized via a whole slide scanner at 1 ΞΌm/pixel resolution [Table 1]. Each slide is accompanied by (a) annotations from an expert pathologist denoting extent of invasive cancer, and (b) RS values denoting good (0 < RS < 18), intermediate (18 β‰¤ RS β‰¤ 30), or poor (30 < RS < 100) outcome.Table 1A summary of the data cohort comprising 29 ER+ BCa patients used in this paper. For each class, the number of patients and the range of oncotype DX RS values are givenClassification StrategyIn each experiment, classification accuracy is computed by comparing the class predictions made by each classifier (multi-FOV and individual FOV sizes) to the ground truth, i.e. good, intermediate, or poor outcome, delineated by the Oncotype DX RS for each slide. To mitigate the bias associated with the selection of training and testing samples, each classifier is evaluated via a three-fold cross-validation scheme.[20] For each experiment, the dataset is first divided randomly into three subsets of equal size. FOVs from two subsets are used to train the preliminary classifier h (via a random forest classifier[21]) and FOVs from the remaining subset is used for evaluation. The training and testing subsets are rotated so that each slide is evaluated once. The entire cross-validation procedure is repeated 10 times to produce mean and standard deviation classification accuracy values.Experiment 1: Multi-FOV Classifier for Quantifying Vascular Density in CD34 IHC Stained HistopathologyThe density of vascular formation is calculated from CD34 IHC stained histology images [Figures 1a and e] to capture the degree of angiogenesis via the following steps.Figure 1(a), (e) CD34 IHC stained images are separated into (b), (f) hematoxylin and (c), (g) DAB channels via color deconvolution. The DAB channel is thresholded to isolate (d), (h) segmented regions expressing the CD34 protein.Step 1: Color deconvolution[15] splits the image into channels representing DAB (i.e. CD34 expression) and hematoxylin [Figures 1b, c, f, and g].Step 2: The DAB channel is thresholded to produce a set of brown pixels corresponding to angiogenic vessels [Figures 1d and h].Step 3: Global vascular density is defined as fraction of brown pixels within region of cancer extent from entire slide.Step 4: Local vascular density is defined as fraction of brown pixels from a smaller FOV (of size Ο„ β�� T) within region of cancer extent. A range of FOV sizes (T= {250, 500, 1000} pixels) was considered in this work.Experiment 2: Multi-FOV Classifier for Quantifying Tissue Morphology on H and E Stained HistopathologyThe variation in the spatial arrangement of cancer nuclei is quantified to capture the BCa tissue structure in an image via the following steps.Step 1: Color deconvolution is used to separate image into channels representing hematoxylin and eosin stains [Figures 2b and c].Figure 2(a) Hematoxylin and eosin stained images are separated into (b) hematoxylin and (c) eosin channels via color deconvolution. The hematoxylin channel is thresholded to detect (d) centroids of individual cancer nuclei, which are used to construct (e), (h), (k) Voronoi diagram, (f), (i), (l) Delaunay triangulation, and (g), (j), (m) minimum spanning tree. The graphs are subsequently used to extract 50 features describing nuclear architecture. Note the variations in nuclear arrangement when exposing (e)-(g) large, (h)-(j) medium, and (k)-(m) small FOVsStep 2: Since hematoxylin stains nuclear material, individual cancer nuclei are detected by thresholding the hematoxylin channel [Figure 2d].Step 3: Cancer nuclei are used as vertices for construction of Voronoi diagram [Figures 2e, h, and k], Delaunay triangulation [Figures 2f, i and l], and minimum spanning tree [Figures 2g, j and m], from which 50 architectural features [Table 2] are extracted for each image.Table 2A breakdown of the 50 architectural features extracted from the Voronoi diagram, Delaunay triangulation, and minimum spanning tree graphsStep 4: Architectural features are calculated for individual FOVs within regions of cancer extent. A wide range of FOV sizes (Ο„ β�� {250, 500, 1000, 2000} pixels) was considered in this paper.Experiment 3: Multi-Parametric Classifier for Combining Features from H and E and IHC Stained HistopathologySince vascular density and nuclear architecture utilize distinct biological phenomena to describe disease aggressiveness, we expect a combination of the two data channels to produce improved classification.Step 1: Perform Experiment 1 and save resulting class decision HIHC
β�� {0,1} made for each slide.Step 2: Perform Experiment 2 and save resulting class decision HHE
β�� {0,1} made for each slide.Step 3: Generate a decision-level prediction Δ¤ = HIHCβ�§HHEβ��{0,1} based on the independent class predictions made from the H and E and IHC stained slides. Note that the β�§ operation is defined as β€�logical ANDβ€�, whereby Δ¤ = 1 if both HIHC=1 and HHE=1. Conversely, Δ¤ = 0 if either HIHC=0 or HHE=0.
</sections.0>

<sections.1>
R  
xperiment 1: ascular ensity in 34  tained istopathology. The ability of the multi-FOV classifier to outperform classification at individual FOV sizes is borne out by the local vascular density [Figure 3], which is able to distinguish entire CD34 IHC stained slides with good vs. poor, good vs. intermediate, and intermediate vs. poor Oncotype DX RS values with classification accuracies of 0.82 Β± 0.04, 0.75 Β± 0.06, 0.86 Β± 0.04, respectively, and positive predictive values (PPV) of 0.82 Β± 0.06, 0.76 Β± 0.06, 0.87 Β± 0.06, respectively. The theoretical justification for the multi-FOV framework suggests that a multi-FOV classifier will outperform the majority of classifiers for individual FOV sizes (theoretical motivation for consensus-based approach ). This concept is validated empirically in Experiment 1, where multi-FOV classifiers perform as well as (and usually better than) individual FOV sizes in both classification accuracy and PPV [Figure 3].Figure 3(a) Classification accuracy and (b) positive predictive values for the multi-FOV framework using local vascular density from 29 CD34 IHC stained histopathology slides over 10 trials of three-fold cross-validation. Note that the bar colors represent different FOV sizes as indicated. For comparison, global vascular density was also calculated directly from each slide.In addition, global vascular density produces corresponding classification accuracies of 0.60 Β± 0.08, 0.40 Β± 0.11, 0.46 Β± 0.07 and PPV of 0.82 Β± 0.09, 0.76 Β± 0.07, and 0.72 Β± 0.11, respectively [Figure 3]. Experiment 1 demonstrates that the multi-FOV classifier (in conjunction with local vascular density) consistently outperforms whole-slide global vascular density in discriminating ER+ BCa with low, intermediate, and high Oncotype DX RS [Figure 3]. The superior performance of the multi-FOV classifier is likely due to its ability to capture local variations in vascular density and robustness to intra-slide heterogeneity. The multi-FOV framework also has an added benefit in that it readily accommodates the inclusion of complimentary structural information (e.g. nuclear architecture).Experiment 2: Tissue Morphology on H and E Stained HistopathologyFigure 4 shows that the architectural features (in conjunction with the multi-FOV classifier) are able to discriminate H and E stained slides with good vs. poor, good vs. intermediate, and intermediate vs. poor Oncotype DX RS at classification accuracies of 0.91 Β± 0.04, 0.72 Β± 0.06, 0.71 Β± 0.11, respectively, and positive predictive values of 0.92 Β± 0.06, 0.74 Β± 0.12, 0.68 Β± 0.11, respectively. The argument in favor of the multi-FOV classifier is even stronger in Experiment 2 (compared to Experiment 1), where it shows significantly increased performance over individual FOV sizes [Figure 4].Figure 4(a) Classification accuracy and (b) positive predictive values for the multi-FOV framework using architectural features from 29 H and E stained histopathology slides over 10 trials of three-fold cross-validation. Note that the bar colors represent different FOV sizes as indicatedExperiment 3: Combined Features on H and E and IHC Stained HistopathologyPerforming a decision-level combination of vascular density and nuclear architecture produces classification accuracies of 0.91 Β± 0.02, 0.76 Β± 0.05, 0.83 Β± 0.08 and PPV of 0.94 Β± 0.10, 0.85 Β± 0.11, 0.92 Β± 0.13, for distinguishing good vs. poor, good vs. intermediate, and intermediate vs. poor RS values, respectively [Table 3]. The fact that vascular density and nuclear architecture exploit such disparate aspects of cancer biology (i.e. angiogenesis and tissue morphology, respectively) suggests that the two feature classes are complimentary and integration will yield improved classification. Experiment 3 shows that a decision-level combination of the two feature sets maintains high levels of classification accuracy while improving positive predictive values [Table 3] over the corresponding multi-FOV classifiers from Experiments 1 and 2 [Figures 3 and 4].Table 3Classification accuracies and positive predictive values for comparing good, intermediate, and poor Oncotype DX scores via the multi-FOV framework using a combination of vascular density and architectural features over 10 trials of three-fold cross-validationSignificance of Multi-FOV Classifier Compared to Individual FOV SizesTo confirm the significance of our results for the multi-FOV classifier, two-sample t-tests were performed with alternative hypotheses asserting that the multi-FOV classifier outperforms individual FOV sizes in terms of classification accuracy [Table 4]. The Bonferroni correction for multiple comparisons[22] has been applied to all P-values in Table 4. For good vs. poor outcome, we were able to reject the null hypothesis for all FOV sizes with P < 0.05 for vascular density and for 3 of 4 FOV sizes for nuclear architecture. Similarly, the null hypothesis was rejected with P < 0.05 for 3 of 4 FOV sizes when comparing good vs. intermediate outcomes and with P < 0.10 for 2 of 4 FOV sizes when comparing intermediate vs. poor outcomes for nuclear architecture. The results also suggest that vascular features in conjunction with the multi-FOV approach do not appear to offer any significant improvement in distinguishing good vs. intermediate and intermediate vs. poor outcomes, suggesting the need to identify higher order features that more accurately quantify vascular formation in IHC stained ER+ BCa histopathology.Table 4Bonferroni-corrected P-values produced by two-sided t-tests with a null hypothesis that classification results from the multi-FOV approach are equivalent to results from individual FOV sizes from both IHC stained and H and E stained histopathology slides. The alternative hypothesis asserts that the multi-FOV classifier performs better than individual FOV sizesUnderstanding Misclassified Patients in the Context of Oncotype DX as a Relative Ground TruthIt is particularly important to note that the Oncotype DX RS values used as class labels in this work represent a relative ground truth due to their demonstrated correlation with patient outcome.[1] The classification results in this paper do not reflect directly upon the ability of the multi-FOV framework to predict patient outcome; instead, they reveal the level of concordance between the multi-FOV framework and Oncotype DX RS values. Specifically, our results demonstrate the difficulty in using relative ground truth to evaluate BCa prognosis due to the high degree of uncertainty in the β€�intermediateβ€� class. This problem is illustrated in Figure 5, where only a few of the misclassified slides with intermediate RS fall squarely within the intermediate class (RS 22-29). Meanwhile, the majority of misclassifications lies on the lower end of the intermediate class (RS 18-21) and may actually represent patients with good prognosis.Figure 5A histogram of patients with intermediate Oncotype DX RS that were found by the multi-FOV classifier to have either good (shown in blue) or poor (shown in red) prognosis
</sections.1>

<sections.2>
C
e have presented a computerized system for predicting disease outcome in + a using only image-based features from multi-parametric histopathology images. rom a translational perspective, this work illustrates the possibility of a low cost, quantitative, image-based risk predictor that performs on par with expensive gene expression assays (e.g. ncotype ) in terms of predicting outcome in + a patients. he main contributions of this work are the following:
 multi- framework that integrates vascular and structural information from multiple s at different sizes in + a histopathology, and
uantitative evaluation of vascular density from 34  stained slides as a prognostic indicator for + a via comparison to ncotype  .
tilizing image features that quantify angiogenesis and nuclear architecture, we demonstrated the ability of the multi- classifier to discriminate between cancers with good and poor , good and intermediate , and intermediate and poor  with accuracies of 0.91, 0.76, and 0.83, respectively. e also establish the importance of using localized -based feature extraction instead of a global approach for classifying heterogeneous histopathology slides. or nuclear architecture, the advantage of the multi- classifier (over classification at individual  sizes) is significant in most cases. owever, the results for vascular density suggest that additional patients should be included to confirm the superiority of the multi- approach.
 closer look at studies misclassified by the multi-parametric multi- classifier shows that a large number of misclassified patients with intermediate  are actually distributed closely along the border between low and intermediate  values. his distinction is particularly important because recent studies comparing ncotype  with another molecular assay, 50, have suggested that a number of patients assigned intermediate  may actually have a low risk of recurrence and, hence, do not require adjuvant chemotherapy.[23]
n the current implementation, the entire algorithm (including object detection/segmentation, feature extraction, and classification) requires approximately 2 h per slide on a 2.83 z processor.  key advantage of the multi- approach, however, is that computational time can be significantly reduced via parallelization, especially with the rapid proliferation of multi-core  and  computing. or instance, individual  sizes (from all histological channels) can be processed in parallel since the class predictions they make are independent of each other.
uture work will focus on incorporating additional feature classes and a larger variety of histopathology studies. n the long term, we aim to perform a direct comparison against ncotype  in terms of predicting patient outcome.CONCLUSIONS
We have presented a computerized system for predicting disease outcome in ER+ BCa using only image-based features from multi-parametric histopathology images. From a translational perspective, this work illustrates the possibility of a low cost, quantitative, image-based risk predictor that performs on par with expensive gene expression assays (e.g. Oncotype DX) in terms of predicting outcome in ER+ BCa patients. The main contributions of this work are the following:
A multi-FOV framework that integrates vascular and structural information from multiple FOVs at different sizes in ER+ BCa histopathology, and
Quantitative evaluation of vascular density from CD34 IHC stained slides as a prognostic indicator for ER+ BCa via comparison to Oncotype DX RS.
Utilizing image features that quantify angiogenesis and nuclear architecture, we demonstrated the ability of the multi-FOV classifier to discriminate between cancers with good and poor RS, good and intermediate RS, and intermediate and poor RS with accuracies of 0.91, 0.76, and 0.83, respectively. We also establish the importance of using localized FOV-based feature extraction instead of a global approach for classifying heterogeneous histopathology slides. For nuclear architecture, the advantage of the multi-FOV classifier (over classification at individual FOV sizes) is significant in most cases. However, the results for vascular density suggest that additional patients should be included to confirm the superiority of the multi-FOV approach.
A closer look at studies misclassified by the multi-parametric multi-FOV classifier shows that a large number of misclassified patients with intermediate RS are actually distributed closely along the border between low and intermediate RS values. This distinction is particularly important because recent studies comparing Oncotype DX with another molecular assay, PAM50, have suggested that a number of patients assigned intermediate RS may actually have a low risk of recurrence and, hence, do not require adjuvant chemotherapy.[23]
In the current implementation, the entire algorithm (including object detection/segmentation, feature extraction, and classification) requires approximately 2 h per slide on a 2.83 GHz processor. A key advantage of the multi-FOV approach, however, is that computational time can be significantly reduced via parallelization, especially with the rapid proliferation of multi-core CPU and GPU computing. For instance, individual FOV sizes (from all histological channels) can be processed in parallel since the class predictions they make are independent of each other.
Future work will focus on incorporating additional feature classes and a larger variety of histopathology studies. In the long term, we aim to perform a direct comparison against Oncotype DX in terms of predicting patient outcome.
</sections.2>

<sections.3>
D/  
 is a majority stockholder in bris nc. and vascu. Vis Inc.
</sections.3>

</text>
