{"name":"Snippet Detector","tagline":" origin https://github.com/MaryGeorgiou/SnippetDetector.git git push -u origin masteBased on a specific biomedical question and given the relevant documents to it, this system will attempt to detect the relevant snippets to the question in each of these documents.","body":"# Project Duration: 30 weeks\r\n\r\n\r\n### 1\r\n* [Project Proposal Report](https://www.dropbox.com/s/bbtx7h7sz6x12cc/georgiou_msc_thesis_proposal.pdf)\r\n* [Relevant Work Study](https://www.dropbox.com/sh/i1i5euc9rzotgjf/AABAiROZybpMEwGeay3ieaZka\">Relevant Work Study</a></li>)\r\n\r\n***\r\n***\r\n\r\n\r\n### 2 - Studying and organizing the data\r\nFor the purposes of this thesis the benchmark datasets released by [BioASQ ](http://www.bioasq.org/) during the challenges of 2013 and 2014 will be used. These datasets contain 782 questions along with their relevant documents and snippets. The questions are distinguished in four categories:\r\n* Yes/no Questions: The \"exact\" answer of such a question is either \"yes\" or \"no\". For instance,\r\n\"Are there any DNMT3 proteins present in plants?\" is a yes/no question.\r\n* Factoid Questions: The \"exact\" answer of such a question is a named entity (e.g., a protein).\r\nFor instance, \"What is the methyl donor of DNA (cytosine-5)-methyltransferases?\" is a\r\nfactoid question.\r\n* List Questions: The \"exact\" answer of such a question is a list of named entities (e.g., a\r\nlist of named entities). For instance, \"Which species may be used for the biotechnological\r\nproduction of itaconic acid?\" is a list question\r\n* Summary Questions: Such a question can be answered only with an \"ideal\" answer (i.e., they\r\ndo not have an \"exact\" answer'). For instance, \\How do histone methyltransferasescause\r\nhistone modication?\" is a summary question.\r\n\r\nIn order to organize the data I decided to create the following java collection:\r\n`Map<String, Map<List<String>, SnippetInstance>> data`\r\nWhere `SnippetInstance` is an Object which represents a set of snippets in a specific document, concerning a specific question. It contains:\r\n* The Question body as a String\r\n* The Question Id to which the snippets are relevant\r\n* The Document Id to which the snippets belongs\r\n* The Text of the above document (Collection<String>)\r\n\r\nA snippet as marked by the experts have the following forms:\r\n* It may be a whole sentence, starting with an uppercase character and ending with period (or questionmark e.t.c.).\r\n* A part of a sentence\r\n* A bunch of sentences where the first and the last is possible not to be complete.\r\n\r\nIn order to be easier to process the above data the snippets were rounded into sentences according to the following process:\r\n* Each snippet, as marked by the experts, was split into sentences with the Stanford sentence splitter.\r\n* For each of the sentences (or sentence pieces) of the first step, the corresponding text sentence was found (the one that contained all the characters of that spesfic piece) and it was set as the \"new snippet\".\r\n\r\nFor example:\r\n**Snippet:** on the next-generation sequencing instrument , at least 350 patients and relatives per run can be simultaneously analyzed in a fast , inexpensive manner.\r\n**Sentence:** By pooling patient genomic DNA before polymerase chain reaction enrichment , indexing samples with bar code tags , and re-sequencing on the next-generation sequencing instrument , at least 350 patients and relatives per run can be simultaneously analyzed in a fast , inexpensive manner .\r\n\r\nSo the snippet is \"rounded\" to the sentence above and is used in this form.\r\n**Training Data:**\r\nQuestions 280,\r\nDocuments 3373,\r\nSentences 34831,\r\nSnippets 4652,\r\n\r\n**Development Data:**\r\nQuestions 281,\r\nDocuments 3540,\r\nSentences 40586,\r\nSnippets 4000,\r\n\r\n**Test Data:**\r\nQuestions 480,\r\nDocuments 6090,\r\nSentences 65568,\r\nSnippets 7976,\r\n\r\n***\r\n***\r\n\r\n\r\n### 3- Decreasing negative instances\r\n One problem of the given data is the huge amount of negative instances (sentences that are not snippets).\r\nIn order to decrease them I subtracted the sentences that have no common words with the query (without taking notice of the stopwords). The result is that for every document at least 10 negative sentences were deleted and very few snippets were lost.\r\n\r\n\r\n\r\n### 4- Baseline Implementation\r\nThe idea is to compute the tf*idf score for every distinct lemma in the documents and then compute the cosine similarity between every question and document sentence. Afterward the goal is to find the score threshold that has the best results in recognizing the correct snippets. \r\n![Cosine Similarity in Training Set](http://i.imgur.com/ma036DH.png)\r\n\r\nWith the new Idf scores:\r\n![Cosine Similarity in Training Set](http://i.imgur.com/ab1Pb2g.png)\r\n![Cosine Similarity in Training Set](http://i.imgur.com/h491OJV.png)\r\n\r\n### 5- Features\r\nn\r\n\r\n ","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}